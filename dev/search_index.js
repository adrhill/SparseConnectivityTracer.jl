var documenterSearchIndex = {"docs":
[{"location":"user/limitations/#limitations","page":"Limitations","title":"Limitations","text":"","category":"section"},{"location":"user/limitations/#Sparsity-patterns-are-conservative-approximations","page":"Limitations","title":"Sparsity patterns are conservative approximations","text":"Sparsity patterns returned by SparseConnectivityTracer (SCT) can in some cases be overly conservative, meaning that they might contain \"too many ones\". If you observe an overly conservative pattern, please open a feature request so we know where to add more method overloads to increase the sparsity.\n\nwarning: SCT's no-false-negatives policy\nIf you ever observe a sparsity pattern that contains too many zeros, we urge you to open a bug report!","category":"section"},{"location":"user/limitations/#Function-must-be-composed-of-generic-Julia-functions","page":"Limitations","title":"Function must be composed of generic Julia functions","text":"SCT can't trace through non-Julia code. However, if you know the sparsity pattern of an external, non-Julia function, you might be able to work around it by adding methods on SCT's tracer types.","category":"section"},{"location":"user/limitations/#Function-types-must-be-generic","page":"Limitations","title":"Function types must be generic","text":"When computing the sparsity pattern of a function, it must be written generically enough to accept numbers of type T<:Real as (or AbstractArray{<:Real}) as inputs.\n\ndetails: Example: Overly restrictive type annotations\nLet's see this mistake in action:using SparseConnectivityTracer\ndetector = TracerSparsityDetector()\n\nrelu_bad(x::AbstractFloat) = max(zero(x), x)\n\nf_bad(xs) = sum(relu_bad, xs)\nnothing # hideSince tracers and dual numbers are Real numbers and not AbstractFloats, relu_bad throws a MethodError:xs = [1.0, -2.0, 3.0];\n\nf_bad(xs)\n\njacobian_sparsity(f_bad, xs, detector)This is easily fixed by loosening type restrictions or adding an additional methods on Real:relu_good(x) = max(zero(x), x)\n\nf_good(xs) = sum(relu_good, xs)\nnothing # hidejacobian_sparsity(f_good, xs, detector)","category":"section"},{"location":"user/limitations/#Limited-control-flow","page":"Limitations","title":"Limited control flow","text":"Only TracerLocalSparsityDetector supports comparison operators (<, ==, ...), indicator functions (iszero, iseven, ...) and control flow.\n\nTracerSparsityDetector does not support any boolean functions and control flow (with the exception of ifelse). This might seem unintuitive but follows from our policy stated above: SCT guarantees conservative sparsity patterns. Using an approach based on operator-overloading, this means that global sparsity detection isn't allowed to hit any branching code. ifelse is the only exception, since it allows us to evaluate both branches.\n\nwarning: Common control flow errors\nBy design, SCT will throw errors instead of returning wrong sparsity patterns. Common error messages include:ERROR: TypeError: non-boolean [tracer type] used in boolean contextERROR: Function [function] requires primal value(s).\nA dual-number tracer for local sparsity detection can be used via `TracerLocalSparsityDetector`.\n\ndetails: Why does TracerSparsityDetector not support control flow and comparisons?\nLet us motivate the design decision above by a simple example function:function f(x)\n    if x[1] > x[2]\n        return x[1]\n    else \n        return x[2]\n    end\nend\nnothing # hideThe desired global Jacobian sparsity pattern over the entire input domain x in mathbbR^2 is [1 1].  Two local sparsity patterns are possible:  [1 0] for x  x_1  x_2, [0 1] for x  x_1 le x_2.The local sparsity patterns of TracerLocalSparsityDetector are easy to compute using operator overloading by using dual numbers  which contain primal values on which we can evaluate comparisons like >:using SparseConnectivityTracer\n\njacobian_sparsity(f, [2, 1], TracerLocalSparsityDetector())\n\njacobian_sparsity(f, [1, 2], TracerLocalSparsityDetector())The global sparsity pattern is impossible to compute when code branches with an if-else condition,  since we can only ever hit one branch during run-time.  If we made comparisons like > return true or false, we'd get the local patterns [1 0] and [0 1] respectively.  But SCT's policy is to guarantee conservative sparsity patterns, which means that \"false positives\" (ones) are acceptable, but \"false negatives\" (zeros) are not. In my our opinion, the right thing to do here is to throw an error:jacobian_sparsity(f, [1, 2], TracerSparsityDetector())In some cases, we can work around this by using ifelse. Since ifelse is a method, it can evaluate \"both branches\" and take a conservative union of both resulting sparsity patterns:f(x) = ifelse(x[1] > x[2], x[1], x[2])\n\njacobian_sparsity(f, [1, 2], TracerSparsityDetector())","category":"section"},{"location":"user/limitations/#stateful-code","page":"Limitations","title":"No guarantee of conservative global sparsity patterns on stateful code","text":"SCT can't guarantee correct, conservative global sparsity patterns on stateful functions f(x) whose output isn't fully determined by the input x. We provide some common examples:\n\ndetails: Example: Stateful branching code\nAs motivated in the section above, global sparsity detection isn't allowed to hit any branching code. While SCT's overloads try to avoid branches by throwing errors, they can in some cases be entered by stateful functions. Let's look at a function whose output doesn't only depend on the input x, but also on an internal state (in this case a random number):using SparseConnectivityTracer\n\nf(x) = randn() > 0.5 ? x[1] : x[2];\n\njacobian_sparsity(f, [1, 2], TracerSparsityDetector())SCT cannot return the correct global sparsity pattern [1 1] for this code. This issue can be circumvented by adding an overload on f that returns a conservative pattern.\n\ndetails: Example: Stateful mutable caches\nProblems can also arise when statefulness is introduced via mutable caches. In this example, we assume a stateful function f whose output not only depends on the input x, but also on a mutable array defined outside of the function call:using SparseConnectivityTracer, SparseArrays\n\nA_cache = sparse([2 0; 0 3])\n\nf(x) = A_cache * x;\n\npattern1 = jacobian_sparsity(f, [1, 2], TracerSparsityDetector())Invalidation of global sparsity patternsWhile this sparsity pattern is correct at the time of detection, it can be invalidated by mutating the array A_cache:A_cache[1, 2] = 4;\n\nA_cache\n\npattern2 = jacobian_sparsity(f, [1, 2], TracerSparsityDetector())With the wisdom of hindsight, pattern1 can therefore be seen as \"non-conservative\".Exception: Dense arraysFor dense caches of type Array (including Matrix and Vector), SCT tries to circumvent this issue by returning a conservative sparsity pattern (note that this behavior could be changed in a future breaking release):A_cache = [2 0; 0 3]\n\npattern1 = jacobian_sparsity(f, [1, 2], TracerSparsityDetector())However, such guarantees can't be made for arbitrary cache types (like the SparseMatrixCSC above).\n\n","category":"section"},{"location":"internals/how_it_works/#how-sct-works","page":"How SparseConnectivityTracer works","title":"How SparseConnectivityTracer works","text":"tip: Read the paper\nPlease read our TMLR paper describing SparseConnectivityTracer: Sparser, Better, Faster, Stronger: Efficient Automatic Differentiation for Sparse Jacobians and Hessians.\n\ndanger: Internals may change\nThe developer documentation might refer to internals which can change without warning in a future release of SparseConnectivityTracer. Only functionality that is exported or part of the user documentation adheres to semantic versioning.","category":"section"},{"location":"internals/how_it_works/#Tracers-are-scalars","page":"How SparseConnectivityTracer works","title":"Tracers are scalars","text":"SparseConnectivityTracer (SCT) works by pushing Real number types called tracers through generic functions using operator overloading. Currently, two tracer types are provided:\n\nGradientTracer: used for Jacobian sparsity patterns\nHessianTracer: used for Hessian sparsity patterns\n\nWhen used alone, these tracers compute global sparsity patterns. Alternatively, these can be used inside of a dual number type Dual,  which keeps track of the primal computation and allows tracing through comparisons and control flow. This is how local sparsity patterns are computed.\n\ntip: Tip: View SparseConnectivityTracer as binary ForwardDiff\nSparseConnectivityTracer's Dual{T, GradientTracer} can be thought of as a binary version of ForwardDiff's own Dual number type.  This is a good mental model for SparseConnectivityTracer if you are familiar with ForwardDiff and its limitations.","category":"section"},{"location":"internals/how_it_works/#Index-sets","page":"How SparseConnectivityTracer works","title":"Index sets","text":"Let's take a look at a scalar function f mathbbR^n rightarrow mathbbR. For a given input mathbfx in mathbbR^n,  the gradient of f is defined as left(nabla f(mathbfx)right)_i = fracpartial fpartial x_i  and the Hessian as left(nabla^2 f(mathbfx)right)_ij = fracpartial^2 fpartial x_i partial x_j. \n\nSparsity patterns correspond to the mask of non-zero values in the gradient and Hessian. Instead of saving the values of individual partial derivatives, they can efficiently be represented by the set of indices corresponding to non-zero values:\n\nGradient patterns are represented by sets of indices lefti big fracpartial fpartial x_i neq 0right\nHessian patterns are represented by sets of index tuples left(i j) Big fracpartial^2 fpartial x_i partial x_j neq 0right\n\nwarning: Global vs. Local\nAs shown in the page \"Global vs. Local\", global sparsity patterns are the index sets over all mathbfxinmathbbR^n, whereas local patterns are the index sets for a given point mathbfx. For a given function f, global sparsity patterns are therefore always supersets of local sparsity patterns  and more \"conservative\" in the sense that they are less sparse. ","category":"section"},{"location":"internals/how_it_works/#Motivating-example","page":"How SparseConnectivityTracer works","title":"Motivating example","text":"Let's take a look at the computational graph of the equation f(mathbfx) = x_1 + x_2x_3 + textsgn(x_4), where textsgn is the sign function:\n\nflowchart LR\n    subgraph Inputs\n    X1[\"$$x_1$$\"]\n    X2[\"$$x_2$$\"]\n    X3[\"$$x_3$$\"]\n    X4[\"$$x_4$$\"]\n    end\n\n    PLUS((+))\n    TIMES((*))\n    SIGN((sgn))\n    PLUS2((+))\n\n    X1 --> |\"{1}\"| PLUS\n    X2 --> |\"{2}\"| TIMES\n    X3 --> |\"{3}\"| TIMES\n    X4 --> |\"{4}\"| SIGN\n    TIMES  --> |\"{2,3}\"| PLUS\n    PLUS --> |\"{1,2,3}\"| PLUS2\n    SIGN --> |\"{}\"| PLUS2\n\n    PLUS2 --> |\"{1,2,3}\"| RES[\"$$y=f(x)$$\"]\n\nTo obtain a sparsity pattern, each scalar input x_i gets seeded with a corresponding singleton index set i [1].  Since addition and multiplication have non-zero derivatives with respect to both of their inputs,  their outputs accumulate and propagate the index sets of their inputs (annotated on the edges of the graph above). The sign function has zero derivatives for any input value. It therefore doesn't propagate the index set 4 corresponding to the input x_4. Instead, it returns an empty set.\n\n[1]: fracpartial x_ipartial x_j neq 0 only holds for i=j\n\nThe resulting global gradient sparsity pattern left(nabla f(mathbfx)right)_i neq 0 for i in 1 2 3 matches the analytical gradient\n\nnabla f(mathbfx) = beginbmatrix\n    fracpartial fpartial x_1 \n    fracpartial fpartial x_2 \n    fracpartial fpartial x_3 \n    fracpartial fpartial x_4\nendbmatrix\n=\nbeginbmatrix\n    1 \n    x_3 \n    x_2 \n    0\nendbmatrix quad \n\ntip: From Global to Local\nNote that the local sparsity pattern could be more sparse in case x_2 and/or x_3 are zero. Computing such local sparsity patterns requires Dual numbers with information about the primal computation.  These are used to evaluate the local differentiability of operations like multiplication.","category":"section"},{"location":"internals/how_it_works/#Toy-implementation","page":"How SparseConnectivityTracer works","title":"Toy implementation","text":"As mentioned above, SCT uses operator overloading to keep track of index sets. Let's start by implementing our own MyGradientTracer type:\n\nstruct MyGradientTracer\n    indexset::Set\nend\n\nWe can now overload operators from Julia Base using our type:\n\nimport Base: +, *, sign\n\nBase.:+(a::MyGradientTracer, b::MyGradientTracer) = MyGradientTracer(union(a.indexset, b.indexset))\nBase.:*(a::MyGradientTracer, b::MyGradientTracer) = MyGradientTracer(union(a.indexset, b.indexset))\nBase.sign(x::MyGradientTracer) = MyGradientTracer(Set()) # return empty index set\n\nLet's create a vector of tracers to represent our input and evaluate our function with it:\n\nf(x) = x[1] + x[2]*x[3] * sign(x[4])\n\nxtracer = [\n    MyGradientTracer(Set(1)),\n    MyGradientTracer(Set(2)),\n    MyGradientTracer(Set(3)),\n    MyGradientTracer(Set(4)),\n]\n\nytracer = f(xtracer)\n\nCompared to this toy implementation, SCT adds some utilities to automatically create xtracer and parse the output ytracer into a sparse matrix, which we will omit here.\n\njacobian_sparsity(f, x, TracerSparsityDetector()) calls these three steps of (1) tracer creation, (2) function evaluation and (3) output parsing in sequence:\n\nusing SparseConnectivityTracer\n\nx = rand(4)\njacobian_sparsity(f, x, TracerSparsityDetector())","category":"section"},{"location":"internals/how_it_works/#Tracing-Jacobians","page":"How SparseConnectivityTracer works","title":"Tracing Jacobians","text":"Our toy implementation above doesn't just work on scalar functions, but also on vector valued functions:\n\ng(x) = [x[1], x[2]*x[3], x[1]+x[4]]\ng(xtracer)\n\nBy stacking individual MyGradientTracers row-wise, we obtain the sparsity pattern of the Jacobian of g\n\nJ_g(mathbfx)=\nbeginpmatrix\n1  0  0  0 \n0  x_3  x_2  0 \n1  0  0  1\nendpmatrix quad \n\nWe obtain the same result using SCT's jacobian_sparsity:\n\njacobian_sparsity(g, x, TracerSparsityDetector())","category":"section"},{"location":"internals/how_it_works/#Tracing-Hessians","page":"How SparseConnectivityTracer works","title":"Tracing Hessians","text":"In the sections above, we outlined how to implement our own GradientTracer from scratch. HessianTracer use the same operator overloading approach but are a bit more involved as they contain two index sets:  one for the gradient pattern and one for the Hessian pattern.  These sets are updated based on whether the first- and second-order derivatives of an operator are zero or not.\n\ntip: To be published\nLook forward to our upcoming publication of SparseConnectivityTracer,  where we will go into more detail on the implementation of HessianTracer!\n\n","category":"section"},{"location":"user/global_vs_local/#global-vs-local","page":"Global vs. Local Sparsity","title":"Global vs. Local Sparsity","text":"Let's motivate the difference between local and global sparsity patterns by taking a look at the function f(mathbfx) = x_1x_2.  The corresponding Jacobian is:\n\nJ_f = beginbmatrix\n    fracpartial fpartial x_1 \n    fracpartial fpartial x_2\nendbmatrix\n=\nbeginbmatrix\n    x_2  x_1\nendbmatrix\n\nDepending on the values of mathbfx, the resulting local Jacobian sparsity pattern could be either:\n\n1 1 for x_1 neq 0, x_2 neq 0\n1 0 for x_1 = 0, x_2 neq 0\n0 1 for x_1 neq 0, x_2 = 0\n0 0 for x_1 = 0, x_2 = 0\n\nThese are computed by TracerLocalSparsityDetector:\n\nusing SparseConnectivityTracer\ndetector = TracerLocalSparsityDetector();\n\nf(x) = x[1]*x[2];\n\njacobian_sparsity(f, [1, 1], detector)\njacobian_sparsity(f, [0, 1], detector)\njacobian_sparsity(f, [1, 0], detector)\njacobian_sparsity(f, [0, 0], detector)\n\nIn contrast to this, TracerSparsityDetector computes a conservative union over all sparsity patterns in mathbfx in mathbbR^2. The resulting global pattern therefore does not depend on the input. All of the following function calls are equivalent:\n\ndetector = TracerSparsityDetector()\n\njacobian_sparsity(f, [1, 1], detector)\njacobian_sparsity(f, [0, 1], detector)\njacobian_sparsity(f, [1, 0], detector)\njacobian_sparsity(f, [0, 0], detector)\njacobian_sparsity(f, rand(2), detector)\n\ntip: Global vs. Local\nGlobal sparsity patterns are the union of all local sparsity patterns over the entire input domain. For a given function, they are therefore always supersets of local sparsity patterns  and more \"conservative\" in the sense that they are less sparse.\n\n","category":"section"},{"location":"internals/adding_overloads/#adding-overloads","page":"Adding Overloads","title":"Adding Overloads","text":"danger: Internals may change\nThe developer documentation might refer to internals which can change without warning in a future release of SparseConnectivityTracer. Only functionality that is exported or part of the user documentation adheres to semantic versioning.\n\nHaving read our guide \"How SparseConnectivityTracer works\", you might want to add your own methods on  GradientTracer,  HessianTracer and Dual to improve the performance of your functions or to work around some of SCT's limitations.\n\nwarning: Don't overload manually\nIf you want to overload a function that takes Real arguments,  we recommend using SCT's code generation mechanism instead of manually adding methods. This page shows you how.","category":"section"},{"location":"internals/adding_overloads/#Generated-overloads","page":"Adding Overloads","title":"Generated overloads","text":"tip: Copy one of our package extensions\nThe easiest way to add overloads is to copy one of our package extensions, e.g. our NNlib extension, and to modify it. Please upstream your additions by opening a pull request! We will help you out to get your feature merged.","category":"section"},{"location":"internals/adding_overloads/#Operator-classification","page":"Adding Overloads","title":"Operator classification","text":"SCT currently supports three types of functions:\n\n1-to-1: operators with one input and one output\n2-to-1: operators with two inputs and one output\n1-to-2: operators with one input and two outputs\n\nDepending on the type of function you're dealing with, you will have to specify the way in which your function is differentiable:\n\nIn Out Examples Methods you need to implement\n1 1 sin, cos, abs is_der1_zero_global, is_der2_zero_global\n2 1 +, *, >, isequal is_der1_arg1_zero_global, is_der2_arg1_zero_global, is_der1_arg2_zero_global, is_der2_arg2_zero_global, is_der_cross_zero_global\n1 2 sincos is_der1_out1_zero_global, is_der2_out1_zero_global, is_der1_out2_zero_global, is_der2_out2_zero_global\n\ndetails: Methods you have to implement for 1-to-1 operators\nFunction Meaning\nis_der1_zero_global(::typeof(f)) = false fracpartial fpartial x neq 0 for some x\nis_der2_zero_global(::typeof(f)) = false fracpartial^2 fpartial x^2 neq 0 for some xOptionally, to increase the sparsity of TracerLocalSparsityDetector, you can additionally implementFunction Meaning\nis_der1_zero_local(::typeof(f), x) = false fracpartial fpartial x neq 0 for given x\nis_der2_zero_local(::typeof(f), x) = false fracpartial^2 fpartial x^2 neq 0 for given xThese fall back to is_der1_zero_local(f::F, x) where {F} = is_der1_zero_global(f)\nis_der2_zero_local(f::F, x) where {F} = is_der2_zero_global(f)\n\ndetails: Methods you have to implement for 2-to-1 operators\nFunction Meaning\nis_der1_arg1_zero_global(::typeof(f)) = false fracpartial fpartial x neq 0 for some xy\nis_der2_arg1_zero_global(::typeof(f)) = false fracpartial^2 fpartial x^2 neq 0 for some xy\nis_der1_arg2_zero_global(::typeof(f)) = false fracpartial fpartial y neq 0 for some xy\nis_der2_arg2_zero_global(::typeof(f)) = false fracpartial^2 fpartial y^2 neq 0 for some xy\nis_der_cross_zero_global(::typeof(f)) = false fracpartial^2 fpartial x partial y neq 0 for some xyOptionally, to increase the sparsity of TracerLocalSparsityDetector, you can additionally implementFunction Meaning\nis_der1_arg1_zero_local(::typeof(f), x, y) = false fracpartial fpartial x neq 0 for given xy\nis_der2_arg1_zero_local(::typeof(f), x, y) = false fracpartial^2 fpartial x^2 neq 0 for given xy\nis_der1_arg2_zero_local(::typeof(f), x, y) = false fracpartial fpartial x neq 0 for given xy\nis_der2_arg2_zero_local(::typeof(f), x, y) = false fracpartial^2 fpartial x^2 neq 0 for given xy\nis_der_cross_zero_local(::typeof(f), x, y) = false fracpartial^2 fpartial x partial y neq 0 for given xyThese fall back to is_der1_arg1_zero_local(f::F, x, y) where {F} = is_der1_arg1_zero_global(f)\nis_der2_arg1_zero_local(f::F, x, y) where {F} = is_der2_arg1_zero_global(f)\nis_der1_arg2_zero_local(f::F, x, y) where {F} = is_der1_arg2_zero_global(f)\nis_der2_arg2_zero_local(f::F, x, y) where {F} = is_der2_arg2_zero_global(f)\nis_der_cross_zero_local(f::F, x, y) where {F} = is_der_cross_zero_global(f)\n\ndetails: Methods you have to implement for 1-to-2 operators\nFunction Meaning\nis_der1_out1_zero_local(::typeof(f)) = false fracpartial f_1partial x neq 0 for some x\nis_der2_out1_zero_local(::typeof(f)) = false fracpartial^2 f_1partial x^2 neq 0 for some x\nis_der1_out2_zero_local(::typeof(f)) = false fracpartial f_2partial x neq 0 for some x\nis_der2_out2_zero_local(::typeof(f)) = false fracpartial^2 f_2partial x^2 neq 0 for some xOptionally, to increase the sparsity of TracerLocalSparsityDetector, you can additionally implementFunction Meaning\nis_der1_out1_zero_local(::typeof(f), x) = false fracpartial f_1partial x neq 0 for given x\nis_der2_out1_zero_local(::typeof(f), x) = false fracpartial^2 f_1partial x^2 neq 0 for given x\nis_der1_out2_zero_local(::typeof(f), x) = false fracpartial f_2partial x neq 0 for given x\nis_der2_out2_zero_local(::typeof(f), x) = false fracpartial^2 f_2partial x^2 neq 0 for given xThese fall back to is_der1_out1_zero_local(f::F, x) where {F} = is_der1_out1_zero_global(f)\nis_der2_out1_zero_local(f::F, x) where {F} = is_der2_out1_zero_global(f)\nis_der1_out2_zero_local(f::F, x) where {F} = is_der1_out2_zero_global(f)\nis_der2_out2_zero_local(f::F, x) where {F} = is_der2_out2_zero_global(f)","category":"section"},{"location":"internals/adding_overloads/#code-gen","page":"Adding Overloads","title":"Generating code","text":"After implementing the required classification methods for a function, the function has not been overloaded on our tracer types yet. SCT provides three functions that generate code via meta-programming:\n\n1-to-1: eval(SCT.generate_code_1_to_1(module_symbol, f))\n2-to-1: eval(SCT.generate_code_1_to_2(module_symbol, f))\n1-to-2: eval(SCT.generate_code_2_to_1(module_symbol, f))\n\nYou are required to call the function that matches your type of operator.\n\ntip: Code generation\nWe will take a look at the code generation mechanism in the example below.","category":"section"},{"location":"internals/adding_overloads/#Example","page":"Adding Overloads","title":"Example","text":"For some examples on how to overload methods, take a look at our package extensions. Let's look at the relu activation function from ext/SparseConnectivityTracerNNlibExt.jl, which is a 1-to-1 operator defined as textrelu(x) = textmax(0 x).","category":"section"},{"location":"internals/adding_overloads/#Step-1:-Classification","page":"Adding Overloads","title":"Step 1: Classification","text":"The relu function has a non-zero first-order derivative fracpartial fpartial x=1 for inputs x0.  The second derivative is zero everywhere. We therefore implement:\n\nimport SparseConnectivityTracer as SCT\nusing NNlib\n\nSCT.is_der1_zero_global(::typeof(relu)) = false\nSCT.is_der2_zero_global(::typeof(relu)) = true\n\nSCT.is_der1_zero_local(::typeof(relu), x) = x < 0\n\nwarning: import SparseConnectivityTracer\nNote that we imported SCT to extend its operator classification methods on typeof(relu).","category":"section"},{"location":"internals/adding_overloads/#Step-2:-Generating-code","page":"Adding Overloads","title":"Step 2: Generating code","text":"The relu function has not been overloaded on our tracer types yet. Let's call the code generation utilities from the \"Generating code\" section for this purpose:\n\neval(SCT.generate_code_1_to_1(:NNlib, relu))\n\nThe relu function is now ready to be called with SCT's tracer types.\n\ndetails: What is the eval call doing?\nLet's call generate_code_1_to_1 without wrapping it eval:SCT.generate_code_1_to_1(:NNlib, relu)As you can see, this returns a quote, a type of expression containing our generated Julia code.We have to use quotes:  The code generation mechanism lives in SCT, but the generated code has to be evaluated in the package extension, not SCT. As you can see in the generated quote, we handle the necessary name-spacing for you.","category":"section"},{"location":"internals/adding_overloads/#Manual-overloads","page":"Adding Overloads","title":"Manual overloads","text":"As mentioned above, for functions that take Real arguments, manual overloads should generally be avoided. If such an overload is necessary (e.g. for array inputs), it should follow the following design priciples, ordered by importance:\n\nLocal sparsity detection (Dual):\n\nOverloads must return conservative sparsity patterns (no false negatives) at the given input.\nLocal tracers are allowed to enter branches in user code. User code can be stateful.\nMethodErrors due to missing overloads can be avoided by returning a very conservative sparsity pattern.\n\nGlobal sparsity detection (GradientTracer and HessianTracer):\n\nOverloads must return conservative sparsity patterns (no false negatives) over the entire input domain.\nTracers must error instead of entering branches in user code.  This requires that overloaded functions return tracers instead of Bool (or numbers),  as the former are designed to error in comparisons.\nOverloads must ignore scalar values of non-tracer inputs. (While not set in stone, changing this rule in the future would require a breaking release.)\nSparsity should be prioritized over performance. We assume global sparsity detection can be amortized.\nMethodErrors due to missing overloads can be avoided by returning a very conservative sparsity pattern.\n\n","category":"section"},{"location":"user/performance/#performance","page":"Performance","title":"Performance","text":"","category":"section"},{"location":"user/performance/#Data-structures-for-sparsity-pattern-representations","page":"Performance","title":"Data structures for sparsity pattern representations","text":"The most efficient internal data structure for sparsity pattern representations depends on the number of inputs and the computational graph / sparsity of a given function.\n\nLet's use a convolutional layer from Flux.jl as an example. By default, SCT uses BitSet for Jacobian sparsity detection, which is well suited for small to medium sized functions.\n\nusing SparseConnectivityTracer, Flux, BenchmarkTools\n\nx = rand(28, 28, 3, 1)\nlayer = Conv((3, 3), 3 => 2)\n\ndetector_bitset = TracerSparsityDetector()\njacobian_sparsity(layer, x, detector_bitset)\n\n@benchmark jacobian_sparsity(layer, x, detector_bitset);\n\nInstead of BitSet, we can use any concrete subtype of AbstractSet{<:Integer}, for example Set{UInt}. To set the sparsity pattern type for Jacobian sparsity detection, we use the keyword argument gradient_pattern_type:\n\ndetector_set = TracerSparsityDetector(; gradient_pattern_type=Set{UInt})\n@benchmark jacobian_sparsity(layer, x, detector_set);\n\nWhile this is slower for the given input size, the performance is highly dependant on the problem. For larger inputs (e.g. of size 224 times 224 times 3 times 1), detector_set will outperform detector_bitset. Note that memory requirement will vary as well.\n\nFor Hessians sparsity detection, the internal sparsity pattern representation uses either concrete subtypes of AbstractDict{I, AbstractSet{I}} or AbstractSet{Tuple{I, I}}, where I <: Integer. By default, Dict{Int, BitSet) is used. To set the sparsity pattern type, use the keyword argument hessian_pattern_type:\n\ndetector = TracerSparsityDetector(; hessian_pattern_type=Dict{UInt, Set{UInt}})\n\nData structures can also be set analogously for TracerLocalSparsityDetector. If both Jacobian and Hessian sparsity patterns are needed,  gradient_pattern_type and hessian_pattern_type can be set separately.\n\n","category":"section"},{"location":"internals/api/#internal-api","page":"Internals Reference","title":"Internals Reference","text":"danger: Internals may change\nThis part of the developer documentation exclusively refers to internals that may change without warning in a future release of SparseConnectivityTracer. Anything written on this page should be treated as if it was undocumented. Only functionality that is exported or part of the user documentation adheres to semantic versioning.\n\n","category":"section"},{"location":"internals/api/#Tracer-Types","page":"Internals Reference","title":"Tracer Types","text":"","category":"section"},{"location":"internals/api/#Traits","page":"Internals Reference","title":"Traits","text":"","category":"section"},{"location":"internals/api/#Utilities","page":"Internals Reference","title":"Utilities","text":"","category":"section"},{"location":"internals/api/#SparseConnectivityTracer.AbstractTracer","page":"Internals Reference","title":"SparseConnectivityTracer.AbstractTracer","text":"AbstractTracer\n\nAbstract supertype of tracers.\n\nType hierarchy\n\nAbstractTracer\n├── GradientTracer\n└── HessianTracer\n\nNote that Dual is not an AbstractTracer.\n\n\n\n\n\n","category":"type"},{"location":"internals/api/#SparseConnectivityTracer.GradientTracer","page":"Internals Reference","title":"SparseConnectivityTracer.GradientTracer","text":"struct GradientTracer{I<:Integer, G<:AbstractSet{I<:Integer}} <: SparseConnectivityTracer.AbstractTracer\n\nReal number type keeping track of non-zero gradient entries.\n\nFields\n\ngradient::AbstractSet{I} where I<:Integer: Set of indices i of non-zero values f(x)_i  0 in the gradient.\nisempty::Bool: Indicator whether gradient in tracer contains only zeros.\n\n\n\n\n\n","category":"type"},{"location":"internals/api/#SparseConnectivityTracer.HessianTracer","page":"Internals Reference","title":"SparseConnectivityTracer.HessianTracer","text":"struct HessianTracer{I<:Integer, G<:AbstractSet{I<:Integer}, H<:Union{AbstractDict{I<:Integer, G<:AbstractSet{I<:Integer}}, AbstractSet{Tuple{I<:Integer, I<:Integer}}}, S<:SparseConnectivityTracer.SharingBehavior} <: SparseConnectivityTracer.AbstractTracer\n\nReal number type keeping track of non-zero gradient and Hessian entries.\n\nFields\n\ngradient::AbstractSet{I} where I<:Integer: Set of indices i of non-zero values f(x)_i  0 in the gradient.\nhessian::Union{AbstractDict{I, G}, AbstractSet{Tuple{I, I}}} where {I<:Integer, G<:AbstractSet{I}}: Set of index-tuples (i j) of non-zero values ²f(x)_ij  0 in the Hessian.\nisempty::Bool: Indicator whether gradient and Hessian in tracer both contain only zeros.\n\n\n\n\n\n","category":"type"},{"location":"internals/api/#SparseConnectivityTracer.Dual","page":"Internals Reference","title":"SparseConnectivityTracer.Dual","text":"struct Dual{P<:Real, T<:SparseConnectivityTracer.AbstractTracer} <: Real\n\nDual Real number type keeping track of the results of a primal computation as well as a tracer.\n\nFields\n\nprimal::Real\ntracer::SparseConnectivityTracer.AbstractTracer\n\n\n\n\n\n","category":"type"},{"location":"internals/api/#SparseConnectivityTracer.NotShared","page":"Internals Reference","title":"SparseConnectivityTracer.NotShared","text":"Indicates that patterns can share memory and operators are prohibited from mutating HessianTracer arguments. In practice, memory sharing is limited to second-order information in HessianTracer.\n\n\n\n\n\n","category":"type"},{"location":"internals/api/#SparseConnectivityTracer.Shared","page":"Internals Reference","title":"SparseConnectivityTracer.Shared","text":"Indicates that patterns always share memory and that operators are allowed to mutate their HessianTracer arguments. In practice, memory sharing is limited to second-order information in HessianTracer.\n\n\n\n\n\n","category":"type"},{"location":"internals/api/#SparseConnectivityTracer.shared","page":"Internals Reference","title":"SparseConnectivityTracer.shared","text":"shared(pattern)\n\nIndicates whether patterns always share memory and whether operators are allowed to mutate their HessianTracer arguments. Returns either the Shared() or NotShared() trait.\n\nIf NotShared(), patterns can share memory and operators are prohibited from mutating HessianTracer arguments.\n\nNote\n\nIn practice, memory sharing is limited to second-order information in HessianTracer.\n\n\n\n\n\n","category":"function"},{"location":"internals/api/#SparseConnectivityTracer.gradient","page":"Internals Reference","title":"SparseConnectivityTracer.gradient","text":"gradient(pattern::AbstractTracer)\n\nReturn a representation of non-zero values f(x)_i  0 in the gradient.\n\n\n\n\n\n","category":"function"},{"location":"internals/api/#SparseConnectivityTracer.hessian","page":"Internals Reference","title":"SparseConnectivityTracer.hessian","text":"hessian(pattern::HessianTracer)\n\nReturn a representation of non-zero values ²f(x)_ij  0 in the Hessian.\n\n\n\n\n\n","category":"function"},{"location":"internals/api/#SparseConnectivityTracer.myempty","page":"Internals Reference","title":"SparseConnectivityTracer.myempty","text":"myempty(T)\nmyempty(tracer::AbstractTracer)\n\nConstructor for an empty tracer or pattern of type T representing a new number (usually an empty pattern).\n\n\n\n\n\n","category":"function"},{"location":"user/api/#api","page":"API Reference","title":"API Reference","text":"SparseConnectivityTracer uses ADTypes.jl's interface for sparsity detection. In fact, the functions jacobian_sparsity and hessian_sparsity are re-exported from ADTypes.\n\nTo compute global sparsity patterns of f(x) over the entire input domain x, use\n\nTo compute local sparsity patterns of f(x) at a specific input x, use","category":"section"},{"location":"user/api/#Memory-allocation","page":"API Reference","title":"Memory allocation","text":"For developers requiring the allocation of output buffers that support our tracers, we additionally provide\n\nPlease note that the DiffCache from PreallocationTools.jl can be used to make caches compatible with both ForwardDiff.jl and SparseConnectivityTracer.jl.\n\n","category":"section"},{"location":"user/api/#ADTypes.jacobian_sparsity","page":"API Reference","title":"ADTypes.jacobian_sparsity","text":"jacobian_sparsity(f, x, sd::AbstractSparsityDetector)::AbstractMatrix{Bool}\njacobian_sparsity(f!, y, x, sd::AbstractSparsityDetector)::AbstractMatrix{Bool}\n\nUse detector sd to construct a (typically sparse) matrix S describing the pattern of nonzeroes in the Jacobian of f (resp. f!) applied at x (resp. (y, x)).\n\n\n\n\n\n","category":"function"},{"location":"user/api/#ADTypes.hessian_sparsity","page":"API Reference","title":"ADTypes.hessian_sparsity","text":"hessian_sparsity(f, x, sd::AbstractSparsityDetector)::AbstractMatrix{Bool}\n\nUse detector sd to construct a (typically sparse) matrix S describing the pattern of nonzeroes in the Hessian of f applied at x.\n\n\n\n\n\n","category":"function"},{"location":"user/api/#SparseConnectivityTracer.TracerSparsityDetector","page":"API Reference","title":"SparseConnectivityTracer.TracerSparsityDetector","text":"TracerSparsityDetector()\n\nGlobal sparsity detection over the entire input domain using SparseConnectivityTracer.jl.  For use with ADTypes.jl's AbstractSparsityDetector interface.\n\nFor local sparsity patterns, use TracerLocalSparsityDetector.\n\nKeyword arguments\n\ngradient_pattern_type::Type:  Data structure used for bookkeeping of gradient sparsity patterns, used in jacobian_sparsity. Supports concrete subtypes of AbstactSet{<:Integer}. Defaults to BitSet.\nhessian_pattern_type::Type:  Data structure used for bookkeeping of Hessian sparsity patterns, used in hessian_sparsity. Supports concrete subtypes of AbstractDict{I, AbstractSet{I}} or AbstractSet{Tuple{I, I}}, where I <: Integer. Defaults to Dict{Int64, BitSet}.\nshared_hessian_pattern::Bool:  Indicate whether second-order information in Hessian sparsity patterns always shares memory and whether operators are allowed to mutate HessianTracers. Defaults to false.\n\nIf support for further pattern representations is needed, please open a feature request: https://github.com/adrhill/SparseConnectivityTracer.jl/issues\n\nExample\n\njulia> using SparseConnectivityTracer\n\njulia> detector = TracerSparsityDetector()\nTracerSparsityDetector()\n\njulia> jacobian_sparsity(diff, rand(4), detector)\n3×4 SparseArrays.SparseMatrixCSC{Bool, Int64} with 6 stored entries:\n 1  1  ⋅  ⋅\n ⋅  1  1  ⋅\n ⋅  ⋅  1  1\n\njulia> f(x) = x[1] + x[2]*x[3] + 1/x[4];\n\njulia> hessian_sparsity(f, rand(4), detector)\n4×4 SparseArrays.SparseMatrixCSC{Bool, Int64} with 3 stored entries:\n ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  1  ⋅\n ⋅  1  ⋅  ⋅\n ⋅  ⋅  ⋅  1\n\nReferences\n\nA. Hill and G. Dalle (2025). \"Sparser, Better, Faster, Stronger: Sparsity Detection for Efficient Automatic Differentiation\"\nA. Hill, G. Dalle, A. Montoison (2025). \"An Illustrated Guide to Automatic Sparse Differentiation\"\n\n\n\n\n\n","category":"type"},{"location":"user/api/#SparseConnectivityTracer.TracerLocalSparsityDetector","page":"API Reference","title":"SparseConnectivityTracer.TracerLocalSparsityDetector","text":"TracerLocalSparsityDetector()\n\nLocal sparsity detection using SparseConnectivityTracer.jl.  For use with ADTypes.jl's AbstractSparsityDetector interface.\n\nFor global sparsity patterns, use TracerSparsityDetector.\n\nKeyword arguments\n\ngradient_pattern_type::Type:  Data structure used for bookkeeping of gradient sparsity patterns, used in jacobian_sparsity. Supports concrete subtypes of AbstactSet{<:Integer}. Defaults to BitSet.\nhessian_pattern_type::Type:  Data structure used for bookkeeping of Hessian sparsity patterns, used in hessian_sparsity. Supports concrete subtypes of AbstractDict{I, AbstractSet{I}} or AbstractSet{Tuple{I, I}}, where I <: Integer. Defaults to Dict{Int64, BitSet}.\nshared_hessian_pattern::Bool:  Indicate whether second-order information in Hessian sparsity patterns always shares memory and whether operators are allowed to mutate HessianTracers. Defaults to false.\n\nIf support for further pattern representations is needed, please open a feature request: https://github.com/adrhill/SparseConnectivityTracer.jl/issues\n\nExample\n\nLocal sparsity patterns are less convervative than global patterns and need to be recomputed for each input x:\n\njulia> using SparseConnectivityTracer\n\njulia> detector = TracerLocalSparsityDetector()\nTracerLocalSparsityDetector()\n\njulia> f(x) = x[1] * x[2]; # J_f = [x[2], x[1]]\n\njulia> jacobian_sparsity(f, [1, 0], detector)\n1×2 SparseArrays.SparseMatrixCSC{Bool, Int64} with 1 stored entry:\n ⋅  1\n\njulia> jacobian_sparsity(f, [0, 1], detector)\n1×2 SparseArrays.SparseMatrixCSC{Bool, Int64} with 1 stored entry:\n 1  ⋅\n\njulia> jacobian_sparsity(f, [0, 0], detector)\n1×2 SparseArrays.SparseMatrixCSC{Bool, Int64} with 0 stored entries:\n ⋅  ⋅\n\njulia> jacobian_sparsity(f, [1, 1], detector)\n1×2 SparseArrays.SparseMatrixCSC{Bool, Int64} with 2 stored entries:\n 1  1\n\nReferences\n\nA. Hill and G. Dalle (2025). \"Sparser, Better, Faster, Stronger: Sparsity Detection for Efficient Automatic Differentiation\"\nA. Hill, G. Dalle, A. Montoison (2025). \"An Illustrated Guide to Automatic Sparse Differentiation\"\n\n\n\n\n\n","category":"type"},{"location":"user/api/#SparseConnectivityTracer.jacobian_eltype","page":"API Reference","title":"SparseConnectivityTracer.jacobian_eltype","text":"jacobian_eltype(x, detector)\n\nAct like eltype(x) but return the matching number type used inside Jacobian sparsity detection.\n\n\n\n\n\n","category":"function"},{"location":"user/api/#SparseConnectivityTracer.hessian_eltype","page":"API Reference","title":"SparseConnectivityTracer.hessian_eltype","text":"hessian_eltype(x, detector)\n\nAct like eltype(x) but return the matching number type used inside Hessian sparsity detection.\n\n\n\n\n\n","category":"function"},{"location":"user/api/#SparseConnectivityTracer.jacobian_buffer","page":"API Reference","title":"SparseConnectivityTracer.jacobian_buffer","text":"jacobian_buffer(x, detector)\n\nAllocate a buffer similiar to x with the required tracer type for Jacobian sparsity detection. Thin wrapper around similar that doesn't expose internal types.\n\n\n\n\n\n","category":"function"},{"location":"user/api/#SparseConnectivityTracer.hessian_buffer","page":"API Reference","title":"SparseConnectivityTracer.hessian_buffer","text":"hessian_buffer(x, detector)\n\nAllocate a buffer similiar to x with the required tracer type for Hessian sparsity detection. Thin wrapper around similar that doesn't expose internal types.\n\n\n\n\n\n","category":"function"},{"location":"#SparseConnectivityTracer.jl","page":"Getting Started","title":"SparseConnectivityTracer.jl","text":" \nDocumentation (Image: Stable) (Image: Dev) (Image: Changelog)\nBuild Status (Image: Build Status) (Image: Coverage) (Image: Aqua) (Image: JET)\nCode Style (Image: Code Style: Runic) (Image: ColPrac: Contributor's Guide on Collaborative Practices for Community Packages)\nDownloads (Image: Downloads) (Image: Dependents)\nCitation (Image: arXiv DOI) (Image: Zenodo DOI)\n\nFast Jacobian and Hessian sparsity pattern detection via operator-overloading.\n\n[!TIP] If you want to use automatic sparse differentiation to compute sparse Jacobians or Hessians with SparseConnectivityTracer (instead of just sparsity patterns),  refer to the DifferentiationInterface.jl documentation.","category":"section"},{"location":"#Installation","page":"Getting Started","title":"Installation","text":"To install this package, open the Julia REPL and run \n\njulia> ]add SparseConnectivityTracer","category":"section"},{"location":"#Examples","page":"Getting Started","title":"Examples","text":"","category":"section"},{"location":"#Jacobian","page":"Getting Started","title":"Jacobian","text":"For functions y = f(x) and f!(y, x), the sparsity pattern of the Jacobian can be obtained by computing a single forward-pass through the function:\n\njulia> using SparseConnectivityTracer\n\njulia> detector = TracerSparsityDetector();\n\njulia> x = rand(3);\n\njulia> f(x) = [x[1]^2, 2 * x[1] * x[2]^2, sin(x[3])];\n\njulia> jacobian_sparsity(f, x, detector)\n3×3 SparseArrays.SparseMatrixCSC{Bool, Int64} with 4 stored entries:\n 1  ⋅  ⋅\n 1  1  ⋅\n ⋅  ⋅  1\n\nBy default, BitSet is used for internal sparsity pattern representations. For very large inputs, it might be more efficient to set the type to Set{UInt}:\n\njulia> detector = TracerSparsityDetector(; gradient_pattern_type=Set{UInt})","category":"section"},{"location":"#Hessian","page":"Getting Started","title":"Hessian","text":"For scalar functions y = f(x), the sparsity pattern of the Hessian can be obtained by computing a single forward-pass through the function:\n\njulia> x = rand(4);\n\njulia> f(x) = x[1] + x[2]*x[3] + 1/x[4];\n\njulia> hessian_sparsity(f, x, detector)\n4×4 SparseArrays.SparseMatrixCSC{Bool, Int64} with 3 stored entries:\n ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  1  ⋅\n ⋅  1  ⋅  ⋅\n ⋅  ⋅  ⋅  1\n\nBy default, dictionaries of BitSets are used for internal sparsity pattern representations. For very large inputs, it might be more efficient to set the type to Dict{UInt, Set{UInt}}:\n\njulia> detector = TracerSparsityDetector(; hessian_pattern_type=Dict{UInt, Set{UInt}})\n\nFor more detailed examples, take a look at the documentation.","category":"section"},{"location":"#Local-tracing","page":"Getting Started","title":"Local tracing","text":"TracerSparsityDetector returns conservative \"global\" sparsity patterns over the entire input domain of x.  It is not compatible with functions that require information about the primal values of a computation (e.g. iszero, >, ==). To compute a less conservative Jacobian or Hessian sparsity pattern at an input point x, use TracerLocalSparsityDetector instead. Note that patterns computed with TracerLocalSparsityDetector depend on the input x and have to be recomputed when x changes:\n\njulia> using SparseConnectivityTracer\n\njulia> detector = TracerLocalSparsityDetector();\n\njulia> f(x) = x[1] > x[2] ? x[1] : x[2];\n\njulia> jacobian_sparsity(f, [1 2], detector)\n1×2 SparseArrays.SparseMatrixCSC{Bool, Int64} with 1 stored entry:\n ⋅  1\n\njulia> jacobian_sparsity(f, [2 1], detector)\n1×2 SparseArrays.SparseMatrixCSC{Bool, Int64} with 1 stored entry:\n 1  ⋅\n\nTake a look at the documentation for more information on global and local patterns.","category":"section"},{"location":"#ADTypes.jl-compatibility","page":"Getting Started","title":"ADTypes.jl compatibility","text":"SparseConnectivityTracer uses ADTypes.jl's interface for sparsity detection, making it compatible with DifferentiationInterface.jl's sparse automatic differentiation functionality. In fact, the functions jacobian_sparsity and hessian_sparsity are re-exported from ADTypes.","category":"section"},{"location":"#Related-packages","page":"Getting Started","title":"Related packages","text":"SparseDiffTools.jl: automatic sparsity detection via Symbolics.jl and Cassette.jl\nSparsityTracing.jl: automatic Jacobian sparsity detection using an algorithm based on SparsLinC by Bischof et al. (1996)","category":"section"},{"location":"#Citation","page":"Getting Started","title":"Citation","text":"If you use SparseConnectivityTracer in your research, please cite our TMLR paper Sparser, Better, Faster, Stronger: Efficient Automatic Differentiation for Sparse Jacobians and Hessians:\n\n@article{hill2025sparser,\n  title={Sparser, Better, Faster, Stronger: Sparsity Detection for Efficient Automatic Differentiation},\n  author={Adrian Hill and Guillaume Dalle},\n  journal={Transactions on Machine Learning Research},\n  issn={2835-8856},\n  year={2025},\n  url={https://openreview.net/forum?id=GtXSN52nIW},\n  note={}\n}","category":"section"},{"location":"#Acknowledgements","page":"Getting Started","title":"Acknowledgements","text":"Adrian Hill gratefully acknowledges funding from the German Federal Ministry of Education and Research under the grant BIFOLD25B.\n\n","category":"section"}]
}
